{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ofnIQRNaCJYe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import nltk\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization, Dense, MaxPooling1D, Conv1D, LSTM, MultiHeadAttention, Flatten, Layer, LayerNormalization, Dropout, Embedding, Input\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HzV4BmzR03b"
      },
      "source": [
        "### Setting up TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6InMzKM1R-03",
        "outputId": "e620e793-58c0-45d6-e251-adef713cc890"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'grpc://10.69.223.74:8470'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.environ['TPU_NAME']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIwIrY6USA5W",
        "outputId": "6976f251-6e94-4d33-e1d7-24021e7e30cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.69.223.74:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.69.223.74:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on TPU:  ['10.69.223.74:8470']\n",
            "Number of accelerators:  8\n"
          ]
        }
      ],
      "source": [
        "tpu_address = os.environ['TPU_NAME']\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "print('Running on TPU: ', tpu.cluster_spec().as_dict()['worker'])\n",
        "print('Number of accelerators: ', strategy.num_replicas_in_sync)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJUgQnE1GX-o"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT_LOUyxGZqZ",
        "outputId": "a33f1313-86cf-4ca1-920c-9c86a2a5492a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k2W3KVeTGyig"
      },
      "outputs": [],
      "source": [
        "datasets_path = \"/content/drive/My Drive/Machine Learning Datasets/Hindi-English\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RP7_raV5HIh6"
      },
      "outputs": [],
      "source": [
        "Hindi_embedding_matrix = np.load(datasets_path + '/Hindi_embedding_matrix.npy')\n",
        "English_embedding_matrix = np.load(datasets_path + '/English_embedding_matrix.npy')\n",
        "\n",
        "Hindi_vectorized_text = np.load(datasets_path + '/Hindi_vectorized.npy')\n",
        "English_vectorized_text = np.load(datasets_path + '/English_vectorized.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnJEVpovHph5",
        "outputId": "9535cf42-f148-4125-e7c6-2092219ace7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Hindi Embeddings Shape =  (20002, 300)\n",
            "    English Embeddings shape = (20002, 300)\n",
            "\n",
            "    Hindi_vectors_shape = (122864, 78)\n",
            "    English_vectors_shape = (122864, 77)\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    f\"\"\"\n",
        "    Hindi Embeddings Shape =  {Hindi_embedding_matrix.shape}\n",
        "    English Embeddings shape = {English_embedding_matrix.shape}\n",
        "\n",
        "    Hindi_vectors_shape = {Hindi_vectorized_text.shape}\n",
        "    English_vectors_shape = {English_vectorized_text.shape}\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TNgtTyBoMgIa"
      },
      "outputs": [],
      "source": [
        "eng_wts = np.load(datasets_path + '/English_Vectorizer_weights.npy', allow_pickle = True)\n",
        "hin_wts = np.load(datasets_path + '/Hindi_Vectorizer_weights.npy', allow_pickle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vSU23NBMLw5a"
      },
      "outputs": [],
      "source": [
        "english_vectorizer = tf.keras.layers.TextVectorization()\n",
        "english_vectorizer.set_vocabulary(eng_wts[0])\n",
        "hindi_vectorizer = tf.keras.layers.TextVectorization()\n",
        "hindi_vectorizer.set_vocabulary(hin_wts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDdscol_NBC9",
        "outputId": "f35ebf32-c8da-4755-a5b2-1e2a11664ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '[UNK]', '<pad>', '<sos>', '<eos>', 'the', 'of', 'and', 'to', 'in', 'a', 'is', 'that', 'was', 'it', 'for', 'this', 'are', 'on', 'as']\n",
            "['', '[UNK]', '<pad>', '<sos>', '<eos>', 'के', 'में', '.', 'की', 'है', 'और', 'से', 'का', ',', 'को', 'हैं', 'एक', 'कि', 'पर', 'भी']\n"
          ]
        }
      ],
      "source": [
        "print(english_vectorizer.get_vocabulary()[:20])\n",
        "print(hindi_vectorizer.get_vocabulary()[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YxrG8AkIhyA"
      },
      "source": [
        "##### Note-\n",
        "    -> Embeddings Dimensions for both Hindi and English texts = 300\n",
        "    -> The Text vectors have a vocab size of 20_000, as we limited it to 20_000 in the keras TextVectorization layer during data preprocessing.\n",
        "    -> The sentence vectors, for hindi has 78 dimensions, while for English there are 77 dimensions.\n",
        "    -> There are 122_864 samples in parallel for both the features(English) and targets(Hindi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "I9IBFsVeQtvy"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "MAX_SEQ_LEN = 77\n",
        "EMBEDDING_DIMS = 300\n",
        "VOCAB_SIZE = Hindi_embedding_matrix.shape[0]                    # Same for both the Hindi and English texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Q0oBGG5bLKNl"
      },
      "outputs": [],
      "source": [
        "def format_dataset(english, hindi):\n",
        "    return (english, hindi[:, :-1], hindi[:, 1:])\n",
        "\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((English_vectorized_text, Hindi_vectorized_text))\n",
        "dataset = dataset.shuffle(200_000)\n",
        "train = dataset.take(100_000)\n",
        "test = dataset.skip(100_000)\n",
        "train = (train.batch(BATCH_SIZE).map(format_dataset)).prefetch(tf.data.AUTOTUNE).cache()\n",
        "test = test.batch(BATCH_SIZE).map(format_dataset).prefetch(tf.data.AUTOTUNE).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usg2DJGP-97m",
        "outputId": "3aa09838-0494-4d8e-c102-245639b58aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_inputs.shape: (64, 77)\n",
            "decoder_inputs.shape: (64, 77)\n",
            "targets.shape: (64, 77)\n"
          ]
        }
      ],
      "source": [
        "for enc_inputs, dec_inputs, targets in train.take(1):\n",
        "    print(f'encoder_inputs.shape: {enc_inputs.shape}')\n",
        "    print(f'decoder_inputs.shape: {dec_inputs.shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbU0mrIBhrYQ"
      },
      "source": [
        "## <center> Masking </center>\n",
        "<p aligh = \"justify\" >Masking is a very simple but important factor in improving the accuracy of a model. It helps to tell a model, which parts of the input data to consider, at a particular Timestep. </p>\n",
        "\n",
        "<br>\n",
        "\n",
        "### <center> Types Of Masks </center>\n",
        "\n",
        "####  Padding Mask\n",
        "<p align = \"justify\">\n",
        "We have already padded our sequences towards the end, to keep the sequence size consistent over the training examples. But, if this data is fed directly to the model, it might get something from the padded portions, which don't even exist in the sequence. So, we send along with our inputs, a padding mask function, that masks the padded region.\n",
        "</p>\n",
        "\n",
        "####  Look Ahead Mask\n",
        "<p align = \"justify\">\n",
        "The Transformer Network has an Encoder-Decoder Architecture. The decoder architecture tries to predict the text for next timestep, only considering the past timesteps. Look Ahead Mask allows us to mask the upcoming sections of the text.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwaBCSA1iPpS",
        "outputId": "80cca2fd-edc7-4f95-d53b-ad6409abc124"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 1., 1., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    ## Adding required dimensions to the padding\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]        # (Batch_size, 1, 1, seq_len)\n",
        "\n",
        "\n",
        "# Working Example\n",
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeAyZ5v6kp6a",
        "outputId": "7e3f9807-7a9d-4fa2-a9b6-7f11a0d76511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.5741197  0.14189708 0.16985106]], shape=(1, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 0. 0.]\n",
            " [1. 1. 0.]\n",
            " [1. 1. 1.]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def create_lookahead_mask(size):\n",
        "    n = int(size * (size+1) / 2)\n",
        "    mask = tfp.math.fill_triangular(tf.ones((n,), dtype=tf.int32), upper=False)\n",
        "    return tf.cast(mask, tf.float32)\n",
        "\n",
        "# Working Example\n",
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_lookahead_mask(x.shape[1])\n",
        "print(x)\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJbGiOgNvAkU"
      },
      "source": [
        "## <center> Positional Encoding </center>\n",
        "<p align = \"justify\">\n",
        "Attention layers see their input as a set of vectors, with no sequential order. This model also doesn't contain any recurrent or convolutional layers. Because of this a \"positional encoding\" is added to give the model some information about the relative position of the tokens in the sentence.<br>\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of tokens in a sentence. So after adding the positional encoding, tokens will be closer to each other based on the similarity of their meaning and their position in the sentence, in the d-dimensional space.\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})} $$\n",
        "<center>\n",
        "<img src = \"https://camo.githubusercontent.com/c279dcae2225189217ab2827711b56b10919d179aead5584e87426de6ee27a67/68747470733a2f2f6a696e676c6573636f64652e6769746875622e696f2f6173736574732f696d672f706f7374732f696c6c75737472617465642d67756964652d7472616e73666f726d65722d31302e6a7067\" width = \"800\"> </center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uylmRIAHC6oy",
        "outputId": "23c1bf70-0863-4c47-cc4d-65a786d80be5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10, 4), dtype=float32, numpy=\n",
              "array([[[ 1.        ,  1.        ,  1.        ,  1.        ],\n",
              "        [ 0.66636676,  0.5403023 ,  0.99995   ,  0.99995   ],\n",
              "        [ 0.6143003 , -0.41614684,  0.9998    ,  0.9998    ],\n",
              "        [ 0.9900591 , -0.9899925 ,  0.99955016,  0.99955004],\n",
              "        [ 0.7270351 , -0.6536436 ,  0.9992005 ,  0.9992001 ],\n",
              "        [ 0.5744009 ,  0.2836622 ,  0.9987513 ,  0.99875027],\n",
              "        [ 0.9612168 ,  0.96017027,  0.9982027 ,  0.99820054],\n",
              "        [ 0.7918362 ,  0.75390226,  0.997555  ,  0.997551  ],\n",
              "        [ 0.5492263 , -0.14550003,  0.9968085 ,  0.99680173],\n",
              "        [ 0.9162743 , -0.91113025,  0.99596363,  0.9959527 ]]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_positional_encoding(num_positions:int, dimensions:int):\n",
        "    \"\"\"\n",
        "    num_positions: Length Of Sequences in the dataset after padding\n",
        "    dimensions: Number of dimensions used to represent each word in embedding matrix\n",
        "    \"\"\"\n",
        "    # Create a column vector for positions\n",
        "    pos_vec = np.arange(num_positions)[:, np.newaxis]\n",
        "    \n",
        "    # Create a row vector for dimensions\n",
        "    dims_vec = np.arange(dimensions)[np.newaxis, :]\n",
        "    \n",
        "    i = dims_vec // 2\n",
        "    angles = pos_vec * 1.0 / (np.power(10_000, 2 * i / np.float32(dimensions)))\n",
        "    angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "    angles[:, 0::1] = np.cos(angles[:, 0::1])\n",
        "    pos_encoding = angles[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "get_positional_encoding(10, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lZRC5lgzX-L"
      },
      "source": [
        "# <center> Transformer </center>\n",
        "<center>\n",
        "<img src = \"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" height = 400></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuy6qMpHSZix"
      },
      "source": [
        "#### Encoder\n",
        "<p align = \"justify\">\n",
        "The Transformer Encoder layer pairs self-attention and convolutional neural network style of processing to improve the speed of training and passes K and V matrices to the Decoder. The inputs are passed through multiple layers of similar structure, to get the outputs to be fed to Decoder. The dimensions of the inputs are secured as they are, because blocks are repeated.\n",
        "</p>\n",
        "###### Steps-\n",
        "    -> Input Sequence is\n",
        "\n",
        "<img src = \"https://jalammar.github.io/images/t/transformer_resideual_layer_norm.png\" height = \"300\"> </img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BEVbnRnQl3qR"
      },
      "outputs": [],
      "source": [
        "class Encoder_Layer(Layer):\n",
        "    def __init__(self, embedding_dims, num_heads, fully_connected_dim,\n",
        "                 dropout_rate = 0.1, layernorm_eps = 1e-6):\n",
        "        super(Encoder_Layer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(num_heads,\n",
        "                                      key_dim = embedding_dims,\n",
        "                                      dropout = dropout_rate)\n",
        "        self.dense1 = Dense(fully_connected_dim, activation = 'relu')\n",
        "        self.dense2 = Dense(embedding_dims)\n",
        "        \n",
        "        self.layer_norm1 = LayerNormalization(epsilon = layernorm_eps)\n",
        "        self.layer_norm2 = LayerNormalization(epsilon = layernorm_eps)\n",
        "\n",
        "        self.dropout_ffn = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        attnout = self.mha(x, x, x, mask)\n",
        "        attnout = self.layer_norm1(x + attnout)\n",
        "\n",
        "        ffn_out = self.dense1(attnout)\n",
        "        ffn_out = self.dense2(attnout)\n",
        "        ffn_out = self.dropout_ffn(ffn_out)\n",
        "        encoder_layer_out = self.layer_norm2(ffn_out + attnout)\n",
        "        return encoder_layer_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PcU1o7zN3F9k"
      },
      "outputs": [],
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self, num_layers, num_heads,\n",
        "                 embedding_dims, fully_connected_dim,\n",
        "                 input_vocab_size, sequence_len,\n",
        "                 dropout_rate = 0.1, layernorm_eps = 1e-6):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.num_layers = num_layers\n",
        "        self.sequence_len = sequence_len\n",
        "        self.embedding = Embedding(input_vocab_size, embedding_dims,\n",
        "                                embeddings_initializer = tf.keras.initializers.Constant(English_embedding_matrix))\n",
        "        \n",
        "        self.positional_encoding = get_positional_encoding(self.sequence_len, embedding_dims)\n",
        "\n",
        "        self.encoding_layers = [Encoder_Layer(\n",
        "                                    embedding_dims = embedding_dims,\n",
        "                                    num_heads = num_heads,                    \n",
        "                                    fully_connected_dim = fully_connected_dim,                                \n",
        "                                    dropout_rate = dropout_rate, layernorm_eps = layernorm_eps\n",
        "                                ) for i in range(self.num_layers)]\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "\n",
        "\n",
        "    def call(self, x, padding_mask = None):\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        ## Scaling the embeddings\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dims, tf.float32))\n",
        "\n",
        "        ## Adding the positional encodings to embeddings\n",
        "        x += self.positional_encoding[:, :self.sequence_len, :]\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Passing x through series of encoder_layers:\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.encoding_layers[i](x, mask = padding_mask)\n",
        "        # x = self.encoding_layers[0](x, mask = padding_mask)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_v8DubIq5Kw",
        "outputId": "65ff74e6-fe09-4a42-bc83-d85b3eec1724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 77, 300)\n"
          ]
        }
      ],
      "source": [
        "sample_encoder = Encoder(num_layers = 2, num_heads = 4,\n",
        "                 embedding_dims = EMBEDDING_DIMS, fully_connected_dim = 512,\n",
        "                 input_vocab_size = VOCAB_SIZE, sequence_len = MAX_SEQ_LEN)\n",
        "temp_input = tf.random.uniform((128, 77), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_padding_mask = create_padding_mask(temp_input)\n",
        "sample_encoder_output = sample_encoder(temp_input, temp_padding_mask)\n",
        "\n",
        "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l8b2ca-ViE5"
      },
      "source": [
        "#### Decoder\n",
        "<p align = \"justify\">\n",
        "Similar to the Encoder, Decoder has multiple decoder_layers.\n",
        "</p>\n",
        "\n",
        "<img src = \"https://www.mihaileric.com/static/output_token-06e143fae69ea58572608d65a546255c-06aef.png\" height = 400></img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yDBZi-NNMOYc"
      },
      "outputs": [],
      "source": [
        "class Decoder_Layer(Layer):\n",
        "    def __init__(self, num_heads, embedding_dims, fully_connected_dim, dropout_rate = 0.1, layernorm_eps = 1e-6):\n",
        "        super(Decoder_Layer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(num_heads, embedding_dims, dropout = dropout_rate)\n",
        "        self.layernorm1 = LayerNormalization(epsilon = layernorm_eps)\n",
        "\n",
        "        self.mha2 = MultiHeadAttention(num_heads, embedding_dims, dropout = dropout_rate)\n",
        "        self.layernorm2 = LayerNormalization(epsilon = layernorm_eps)\n",
        "\n",
        "        self.dense1 = Dense(fully_connected_dim, activation = 'relu')\n",
        "        self.dense2 = Dense(embedding_dims)\n",
        "        self.dropout_ = Dropout(dropout_rate)\n",
        "        self.layernorm3 = LayerNormalization(epsilon = layernorm_eps)\n",
        "\n",
        "    def call(self, x, encoder_out, padding_mask, lookahead_mask):\n",
        "        attn1_out = self.mha1(x, x, x, lookahead_mask)\n",
        "        attn1_out = self.layernorm1(x + attn1_out)\n",
        "\n",
        "        attn2_out = self.mha2(attn1_out, encoder_out, encoder_out, padding_mask)\n",
        "        attn2_out = self.layernorm2(attn1_out + attn2_out)\n",
        "\n",
        "        dense_out = self.dense1(attn2_out)\n",
        "        dense_out = self.dense2(dense_out)\n",
        "        dense_out = self.dropout_(dense_out)\n",
        "\n",
        "        decoder_out = self.layernorm3(dense_out + attn2_out)\n",
        "        return decoder_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "s8JWwgIqjrdX"
      },
      "outputs": [],
      "source": [
        "class Decoder(Layer):\n",
        "    def __init__(self, num_layers, num_heads,\n",
        "                 embedding_dims, fully_connected_dim,\n",
        "                 output_vocab_size, sequence_length,\n",
        "                 dropout_rate = 0.1,\n",
        "                 layernorm_eps = 1e-6\n",
        "                 ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.seq_len = sequence_length\n",
        "        self.embedding_dims = embedding_dims\n",
        "\n",
        "        self.embedding = Embedding(output_vocab_size, embedding_dims,\n",
        "                            embeddings_initializer = tf.keras.initializers.Constant(Hindi_embedding_matrix))\n",
        "        self.positional_encoding = get_positional_encoding(sequence_length, embedding_dims)\n",
        "\n",
        "        self.decoder_layers = [Decoder_Layer(num_heads, embedding_dims,\n",
        "                                              fully_connected_dim, dropout_rate,\n",
        "                                              layernorm_eps) for i in range(num_layers)]\n",
        "\n",
        "\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "        self.output_layer = Dense(VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "    def call(self, x, encoder_out, padding_mask, lookahead_mask):\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dims, tf.float32))\n",
        "        x += self.positional_encoding[:, :self.seq_len, :]\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.decoder_layers[i]( x, encoder_out, padding_mask, lookahead_mask)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7X8vcyM3NH5",
        "outputId": "ba6915f4-8b5a-45d2-c113-f837c0329aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(77, 77)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([128, 77, 20002])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_lookahead_mask = create_lookahead_mask(77)\n",
        "print(temp_lookahead_mask.shape)\n",
        "sample_decoder = Decoder(num_layers = 2, num_heads = 4,\n",
        "                 embedding_dims = EMBEDDING_DIMS, fully_connected_dim = 512,\n",
        "                 output_vocab_size = VOCAB_SIZE, sequence_length = MAX_SEQ_LEN)\n",
        "\n",
        "\n",
        "output = sample_decoder(temp_input, sample_encoder_output, temp_padding_mask, temp_lookahead_mask)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9SL8nMGDoVz"
      },
      "source": [
        "### Assembling The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ppTgDeuB6te3"
      },
      "outputs": [],
      "source": [
        "class Transformer_Model(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, sequence_length,\n",
        "                 num_encoder_layers = 2, num_encoder_heads = 4,\n",
        "                 input_embedding_dims = EMBEDDING_DIMS, fully_connected_dim = EMBEDDING_DIMS,\n",
        "                 input_vocab_size = VOCAB_SIZE, num_decoder_layers = 2, num_decoder_heads = 4,\n",
        "                 output_embedding_dims = EMBEDDING_DIMS, output_vocab_size = VOCAB_SIZE\n",
        "                 ):\n",
        "        super(Transformer_Model, self).__init__()\n",
        "        self.lookahead_mask = create_lookahead_mask(sequence_length)\n",
        "\n",
        "        self.encoder_ = Encoder(num_encoder_layers, num_encoder_heads, input_embedding_dims,\n",
        "                        fully_connected_dim, input_vocab_size, sequence_length,\n",
        "                        dropout_rate = 0.3)\n",
        "        \n",
        "\n",
        "        self.decoder_ = Decoder(num_decoder_layers, num_decoder_heads,\n",
        "                    output_embedding_dims, fully_connected_dim,\n",
        "                    output_vocab_size, sequence_length,\n",
        "                    dropout_rate = 0.3)\n",
        "            \n",
        "\n",
        "    def call(self, encoder_inputs, decoder_inputs):\n",
        "        encoder_padding_mask = create_padding_mask(encoder_inputs)\n",
        "        decoder_padding_mask = create_padding_mask(decoder_inputs)\n",
        "        encoder_out = self.encoder_(encoder_inputs, encoder_padding_mask)\n",
        "        decoder_out = self.decoder_(decoder_inputs, encoder_out, decoder_padding_mask, self.lookahead_mask)\n",
        "        return decoder_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "u9-QYx7Mq7pn"
      },
      "outputs": [],
      "source": [
        "sample_transformer = Transformer_Model(77)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOb_cYEvowsc",
        "outputId": "41e69cdf-8faf-445f-eafc-07fcbc2343fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 77, 20002])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_enc_input = tf.random.uniform((64, 77), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_dec_input = tf.random.uniform((64, 77), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output = sample_transformer(temp_enc_input, temp_dec_input)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY3KImFaJh5J",
        "outputId": "17ba0ff4-1e77-4998-fa46-da8666797711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer__model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  9252000   \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  18161602  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,413,602\n",
            "Trainable params: 27,413,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "sample_transformer.summary()\n",
        "del(sample_transformer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUSfDq7SOEhX"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jMPS8QAtOHYR"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    transformer = Transformer_Model(MAX_SEQ_LEN)\n",
        "\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        reduction = tf.keras.losses.Reduction.NONE\n",
        "    )\n",
        "\n",
        "    def compute_loss(labels, predictions):\n",
        "        per_example_loss = loss_object(labels, predictions)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size = BATCH_SIZE * strategy.num_replicas_in_sync)\n",
        "\n",
        "\n",
        "    test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "\n",
        "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
        "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')\n",
        "\n",
        "    lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate = 0.001,\n",
        "        decay_steps = 50,\n",
        "        decay_rate = 0.9\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
        "\n",
        "    @tf.function                                                                # Converts the function in graph mode for faster execution\n",
        "    def distributed_training_step(datasets_inputs):\n",
        "        per_replica_losses = strategy.run(train_steps, args = (datasets_inputs, ))\n",
        "        print(per_replica_losses)\n",
        "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis = None)\n",
        "\n",
        "    @tf.function\n",
        "    def distributed_test_step(datasets_inputs):\n",
        "        strategy.run(test_steps, args = (datasets_inputs, ))\n",
        "\n",
        "    def train_steps(inputs):\n",
        "        encoder_inputs, decoder_inputs, targets = inputs\n",
        "\n",
        "        # Shape of images here -> [128, 224, 224, 3]  with 128 being batch size.\n",
        "        # Shape of Labels here -> (128, 9) representing 9 classes.\n",
        "\n",
        "        with tf.GradientTape() as tape:                                         # To keep in check gradients of weights and biases(kernel)\n",
        "            predictions = transformer(encoder_inputs, decoder_inputs)\n",
        "            loss = compute_loss(targets, predictions)\n",
        "\n",
        "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))    # Applying changes in weights and biases.\n",
        "\n",
        "        train_accuracy.update_state(targets, predictions)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_steps(inputs):\n",
        "        encoder_inputs, decoder_inputs, targets = inputs\n",
        "\n",
        "        predictions = transformer(encoder_inputs, decoder_inputs)\n",
        "        loss = loss_object(targets, predictions)\n",
        "\n",
        "        test_loss.update_state(loss)\n",
        "        test_accuracy.update_state(targets, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0E5I6QGkXqN",
        "outputId": "e5d52312-8907-4f87-fec9-1dd71de4ac33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer__model_1/encoder_2/encoder__layer_4/dense_18/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_4/dense_18/bias:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer__model_1/encoder_2/encoder__layer_4/dense_18/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_4/dense_18/bias:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PerReplica:{\n",
            "  0: Tensor(\"output_0_shard_0:0\", shape=(), dtype=float32),\n",
            "  1: Tensor(\"output_0_shard_1:0\", shape=(), dtype=float32),\n",
            "  2: Tensor(\"output_0_shard_2:0\", shape=(), dtype=float32),\n",
            "  3: Tensor(\"output_0_shard_3:0\", shape=(), dtype=float32),\n",
            "  4: Tensor(\"output_0_shard_4:0\", shape=(), dtype=float32),\n",
            "  5: Tensor(\"output_0_shard_5:0\", shape=(), dtype=float32),\n",
            "  6: Tensor(\"output_0_shard_6:0\", shape=(), dtype=float32),\n",
            "  7: Tensor(\"output_0_shard_7:0\", shape=(), dtype=float32)\n",
            "}\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer__model_1/encoder_2/encoder__layer_4/dense_18/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_4/dense_18/bias:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer__model_1/encoder_2/encoder__layer_4/dense_18/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_4/dense_18/bias:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PerReplica:{\n",
            "  0: Tensor(\"output_0_shard_0:0\", shape=(), dtype=float32),\n",
            "  1: Tensor(\"output_0_shard_1:0\", shape=(), dtype=float32),\n",
            "  2: Tensor(\"output_0_shard_2:0\", shape=(), dtype=float32),\n",
            "  3: Tensor(\"output_0_shard_3:0\", shape=(), dtype=float32),\n",
            "  4: Tensor(\"output_0_shard_4:0\", shape=(), dtype=float32),\n",
            "  5: Tensor(\"output_0_shard_5:0\", shape=(), dtype=float32),\n",
            "  6: Tensor(\"output_0_shard_6:0\", shape=(), dtype=float32),\n",
            "  7: Tensor(\"output_0_shard_7:0\", shape=(), dtype=float32)\n",
            "}\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer__model_1/encoder_2/encoder__layer_4/dense_18/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_4/dense_18/bias:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer__model_1/encoder_2/encoder__layer_4/dense_18/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_4/dense_18/bias:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/kernel:0', 'transformer__model_1/encoder_2/encoder__layer_5/dense_20/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PerReplica:{\n",
            "  0: Tensor(\"output_0_shard_0:0\", shape=(), dtype=float32),\n",
            "  1: Tensor(\"output_0_shard_1:0\", shape=(), dtype=float32),\n",
            "  2: Tensor(\"output_0_shard_2:0\", shape=(), dtype=float32),\n",
            "  3: Tensor(\"output_0_shard_3:0\", shape=(), dtype=float32),\n",
            "  4: Tensor(\"output_0_shard_4:0\", shape=(), dtype=float32),\n",
            "  5: Tensor(\"output_0_shard_5:0\", shape=(), dtype=float32),\n",
            "  6: Tensor(\"output_0_shard_6:0\", shape=(), dtype=float32),\n",
            "  7: Tensor(\"output_0_shard_7:0\", shape=(), dtype=float32)\n",
            "}\n",
            "Epoch 1, Loss: 155.57, Accuracy: 78.19, Test Loss: 0.19, Test Accuracy: 79.08, \t Elapsed Time: 215\n",
            "Epoch 2, Loss: 114.19, Accuracy: 79.65, Test Loss: 0.19, Test Accuracy: 79.56, \t Elapsed Time: 132\n",
            "Epoch 3, Loss: 113.27, Accuracy: 79.73, Test Loss: 0.18, Test Accuracy: 79.63, \t Elapsed Time: 132\n",
            "Epoch 4, Loss: 113.18, Accuracy: 79.76, Test Loss: 0.18, Test Accuracy: 79.63, \t Elapsed Time: 132\n",
            "Epoch 5, Loss: 113.18, Accuracy: 79.76, Test Loss: 0.18, Test Accuracy: 79.63, \t Elapsed Time: 133\n",
            "Epoch 6, Loss: 113.18, Accuracy: 79.76, Test Loss: 0.18, Test Accuracy: 79.63, \t Elapsed Time: 132\n",
            "Epoch 7, Loss: 113.18, Accuracy: 79.76, Test Loss: 0.18, Test Accuracy: 79.63, \t Elapsed Time: 132\n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 10\n",
        "with strategy.scope():\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_start = datetime.now()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Training Loop\n",
        "        for x in train: \n",
        "            total_loss += distributed_training_step(x)\n",
        "            num_batches += 1\n",
        "\n",
        "        train_loss = total_loss / num_batches\n",
        "\n",
        "        # Testing Loop\n",
        "        for x in test:\n",
        "            distributed_test_step(x)\n",
        "\n",
        "        epoch_end = datetime.now()\n",
        "        \n",
        "        template = (\"Epoch {}, Loss: {:.2f}, Accuracy: {:.2f}, Test Loss: {:.2f}, Test Accuracy: {:.2f}, \\t Elapsed Time: {}\")\n",
        "\n",
        "        print(template.format(\n",
        "            epoch + 1,\n",
        "            train_loss,\n",
        "            train_accuracy.result() * 100,\n",
        "            test_loss.result() / strategy.num_replicas_in_sync,\n",
        "            test_accuracy.result() * 100,\n",
        "            (epoch_end - epoch_start).seconds\n",
        "        ))\n",
        "\n",
        "        test_loss.reset_states()\n",
        "        train_accuracy.reset_states()\n",
        "\n",
        "        test_accuracy.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr-iWjL3lHJy"
      },
      "outputs": [],
      "source": [
        "### Runtime disconnected while running😑😑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PkvLGVkODoy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Machine_Translation_Transformers.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
